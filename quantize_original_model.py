from furiosa_llm.optimum import QuantizerForCausalLM, QuantizationConfig
from furiosa_llm.optimum.dataset_utils import create_data_loader

def main():
    # ìˆœì • ëª¨ë¸ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    model_id = "meta-llama/Llama-3.3-70B-Instruct"
    # ì–‘ìí™”ëœ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ
    quantized_model_output_dir = "./quantized_original_llama"

    print(f"'{model_id}' ìˆœì • ëª¨ë¸ì˜ ì–‘ìí™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    dataloader = create_data_loader(
        tokenizer=model_id,
        dataset_name_or_path="mit-han-lab/pile-val-backup",
        dataset_split="validation",
        num_samples=5,
        max_sample_length=2048,
    )

    quantizer = QuantizerForCausalLM.from_pretrained(model_id)
    
    quantizer.quantize(
        quantized_model_output_dir,
        dataloader,
        QuantizationConfig.w_f8_a_f8_kv_f8()
    )

    print(f"\nğŸ‰ ìˆœì • ëª¨ë¸ ì–‘ìí™” ì„±ê³µ! ê²°ê³¼ê°€ '{quantized_model_output_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    main()
